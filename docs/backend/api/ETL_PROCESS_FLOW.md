# ETL Process Flow: Supabase + pg-boss + Trigger

## Общая архитектура

- **API**: Принимает массив продаж, сохраняет "сырые" данные в таблицу `sales_input`.
- **Postgres (Supabase)**: После каждой вставки в `sales_input` триггер вызывает функцию, которая ставит задачу в очередь pg-boss (`process-sale-record`).
- **pg-boss**: Очередь задач, реализованная на базе PostgreSQL.
- **Node.js worker**: Слушает очередь, обрабатывает задачи ETL, нормализует данные и переносит их в основные таблицы.

---

## Подробная последовательность

1. **Поступление данных**
    - Клиент/сервис отправляет данные о продажах через API.
    - API сохраняет каждую запись "как есть" в таблицу `sales_input`.

2. **Триггер в БД**
    - После каждой вставки в `sales_input` срабатывает триггер `sales_input_after_insert`.
    - Триггер вызывает функцию `trigger_sales_input_etl`, которая ставит задачу в очередь pg-boss с payload `{ recordId: NEW.id }`.

3. **Очередь pg-boss**
    - Задача с типом `process-sale-record` и payload `{ recordId }` появляется в очереди.
    - Очередь гарантирует доставку задачи и поддерживает retry/отложенные задачи.

4. **Node.js worker**
    - Воркер стартует и подписывается на очередь `process-sale-record` через pg-boss.
    - Для каждой задачи:
        1. Начинает транзакцию.
        2. Получает запись из `sales_input` по `recordId`.
        3. Параллельно ищет/создаёт:
            - Продукт (и вложенные справочники: производитель, категория, группа, вид)
            - Поставщика
            - Локацию
        4. Создаёт нормализованную запись в таблице `operations`.
        5. Помечает исходную запись в `sales_input` как обработанную (`is_processed = true`, `processed_at = now()`).
        6. Фиксирует транзакцию. В случае ошибки — откатывает транзакцию и задача будет повторена.
        7. Логирует ключевые этапы (start, success, error).

5. **Повторные попытки и надежность**
    - Если обработка задачи завершилась с ошибкой, pg-boss автоматически повторит задачу согласно своей retry-стратегии.
    - Все операции атомарны благодаря транзакциям.

---

## Преимущества подхода
- **Надежность**: Нет потери задач между API и обработчиком, всё в рамках одной БД.
- **Масштабируемость**: Можно запускать несколько воркеров.
- **Простота поддержки**: Нет отдельного брокера (Redis), всё на Postgres.
- **Гибкость**: Легко расширять ETL-логику, добавлять новые справочники и этапы.

---

## Диаграмма (упрощённая)

```
Client/API
   |
   v
[sales_input] <--- INSERT
   |
   v
[Trigger + Function]
   |
   v
[pg-boss queue]
   |
   v
[Node.js worker]
   |
   v
[operations, products, ...]
```

---

## Краткое описание ключевых компонентов

- **sales_input**: staging-таблица для "сырых" данных.
- **operations**: основная таблица нормализованных операций.
- **pg-boss**: очередь задач внутри Postgres.
- **trigger_sales_input_etl**: функция, ставящая задачи в очередь.
- **worker.js**: Node.js-воркер, реализующий ETL-логику.

---

## Ожидаемое поведение
- Любая новая запись в `sales_input` автоматически и гарантированно будет обработана ETL-воркером.
- В случае ошибок задача будет повторяться до успешной обработки.
- Все справочники (продукты, поставщики, локации и т.д.) поддерживаются в актуальном состоянии.
- Вся цепочка полностью автоматизирована и не требует ручного вмешательства. 